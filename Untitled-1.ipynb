{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file_name, isTrain):\n",
    "    train = pd.read_csv(file_name)\n",
    "    #if isTrain:\n",
    "        # link in present only in train dataset\n",
    "        #train = train.drop(['link'], axis=1)\n",
    "    fields = ['date','city', 'latitude', 'longitude','Kateqoriya', 'Mərtəbə', 'Sahə', 'Çıxarış', 'Otaq sayı', 'Təmir', 'İpoteka', 'locations']\n",
    "    if isTrain:\n",
    "        fields.append('price')\n",
    "    train = train[fields]\n",
    "\n",
    "    # clean data to make it readable for the algorithm\n",
    "    train.replace('var', True, inplace=True)\n",
    "    train.replace('yoxdur', False, inplace=True)\n",
    "    train.replace(np.nan, False, inplace=True)\n",
    "    train.replace({'m²': ''}, regex=True, inplace=True)\n",
    "    train.replace('Yeni tikili', True, inplace=True)\n",
    "    train.replace('Köhnə tikili', False, inplace=True)\n",
    "    train = train.astype({\"Sahə\": float})\n",
    "    currentFloors = []\n",
    "    maxFloors = []\n",
    "    for floor in train['Mərtəbə'].array:\n",
    "        floors = floor.split(' / ')\n",
    "        currentFloors.append(floors[0])\n",
    "        maxFloors.append(floors[1])\n",
    "    train[\"current_floor\"] = currentFloors\n",
    "    train[\"max_floor\"] = maxFloors\n",
    "    \n",
    "    train = train.astype({\"current_floor\": int})\n",
    "    train = train.astype({\"max_floor\": int})\n",
    "    del train['Mərtəbə']\n",
    "    \n",
    "    day = []\n",
    "    month = []\n",
    "    year = []\n",
    "    for index in range(0, len(train['date'].array)):\n",
    "        element = train['date'].array[index]\n",
    "        values = element.split(' ')\n",
    "        if values[1] == 'Yanvar':\n",
    "            month.append(1)\n",
    "        elif values[1] == 'Dekabr':\n",
    "            month.append(0)\n",
    "        elif values[1] == 'Noyabr':\n",
    "            month.append(11)\n",
    "        elif values[1] == 'Oktyabr':\n",
    "            month.append(10)\n",
    "        elif values[1] == 'Sentyabr':\n",
    "            month.append(9)\n",
    "        elif values[1] == 'May':\n",
    "            month.append(5)\n",
    "        elif values[1] == 'Aprel':\n",
    "            month.append(4)\n",
    "        elif values[1] == 'Mart':\n",
    "            month.append(3)\n",
    "        elif values[1] == 'Fevral':\n",
    "            month.append(2)\n",
    "\n",
    "        if values[0] == 'Dünən' or values[0] == 'Bugün':\n",
    "            month.append(3)\n",
    "            year.append(2023)\n",
    "            if values[0] == 'Dünən':\n",
    "                day.append(25)\n",
    "            else:\n",
    "                day.append(26)\n",
    "        else:\n",
    "            day.append(values[0])\n",
    "        if values[2] == '2022':\n",
    "            year.append(0)\n",
    "        elif values[2] == '2023':\n",
    "            year.append(1)\n",
    "    del train['date']\n",
    "    train['day'] = day\n",
    "    train['month'] = month\n",
    "    train['year'] = year\n",
    "\n",
    "    return train\n",
    "train = process('3-3.1.csv', True)\n",
    "\n",
    "subways = ([\"28 / Jafar Jabbarli\", 40.38278310227317, 49.84679519744824], [\"Sahil\", 40.371974998746005, 49.84405620938562], [\"Icherisheher\", 40.366106296864864, 49.83165260854011],\n",
    "            [\"Nizami\", 40.37966172913042, 49.83028696791216], [\"Elmler\", 40.37519653577367, 49.8144159839544], \n",
    "            [\"Inshaatcilar\", 40.390286712687086, 49.80266890649604], [\"Khatai\", 40.38367997016057, 49.87198948221093],\n",
    "            [\"Ganjlik\", 40.400695138059746, 49.85158561279074], [\"Nariman Narimanov\", 40.40564344658408, 49.87084158387418,],\n",
    "            [\"Ulduz\", 40.40564344658408, 49.87084158387418], [\"Gara Garayev\", 40.42279507348184, 49.93486614333679],\n",
    "            [\"Neftchiler\", 40.41035399448429, 49.943230123780445], [\"Khalglar Dostlughu\", 40.39809074592212, 49.95193378892042],\n",
    "            [\"Ahmadli\", 40.38683318229922, 49.952825746241025], [\"Hazi Aslanov\", 40.374117636572144, 49.95359028108725], \n",
    "            [\"Memar Ajami\", 40.41279738674918, 49.81461894228935], [\"Avtovagzal\", 40.42419787524228, 49.79508704280422], \n",
    "            [\"Nasimi\", 40.42419787524228, 49.79508704280422], [\"8 noyabr\", 40.40357644851948, 49.82034830011121], \n",
    "            [\"Azadlig\", 40.42707247607273, 49.84235424019779], [\"Darnaghul\", 40.42647774116251, 49.86136528902999],\n",
    "            [\"Khojasan\", 40.42191793220399, 49.778680247211376], [\"Koroghlu\", 40.42063419443794, 49.91767945403461],\n",
    "            [\"Bakmil\", 40.41511995175986, 49.878749137199726], [\"20 yanvar\", 40.40437043171568, 49.808554290309566])\n",
    "\n",
    "houses = list(zip(train['latitude'], train['longitude']))\n",
    "\n",
    "min_distances = []\n",
    "distances = []\n",
    "for i in range(len(houses)):\n",
    "    distances.append([])\n",
    "    for j in range(len(subways)):\n",
    "        \n",
    "        delta_x = houses[i][0]-subways[j][1]\n",
    "        delta_y = houses[i][1]-subways[j][2]\n",
    "        distance = (delta_x**2 + delta_y**2)**(0.5)\n",
    "        distances[i].append(distance)\n",
    "    min_idx = distances[i].index(min(distances[i]))\n",
    "    min_distances.append(min(distances[i]) * 111000)\n",
    "    #print('closest subway to house number', i, ' at ', houses[i], 'is subway ', subways[min_idx], ' number ', min_idx, ' at ',  min(distances[i]))\n",
    "train['distances'] = min_distances\n",
    "\n",
    "tags = train[\"locations\"]\n",
    "clean_tags = tags.str.strip('[]\\'').str.split('\\', \\'')\n",
    "a = clean_tags.apply(pd.Series)\n",
    "b = a.stack()\n",
    "c = pd.get_dummies(b)\n",
    "d = c.groupby(level=0).sum()\n",
    "\n",
    "train = train.join(d)\n",
    "train = train.drop(['locations'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('with_disstance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = process('test_binaaz_updated.csv', False)\n",
    "tags = test[\"location attributes\"]\n",
    "test_clean_tags = tags.str.strip('[]\\'').str.split('\\', \\'')\n",
    "a = test_clean_tags.apply(pd.Series)\n",
    "b = a.stack()\n",
    "c = pd.get_dummies(b)\n",
    "d = c.groupby(level=0).sum()\n",
    "\n",
    "tags = set()\n",
    "for ls in clean_tags:\n",
    "   for tag in ls:\n",
    "    tags.add(tag)\n",
    "\n",
    "test_tags = set()\n",
    "for ls in test_clean_tags:\n",
    "   for tag in ls:\n",
    "    test_tags.add(tag)\n",
    "\n",
    "to_add = tags.difference(test_tags)\n",
    "empty = []\n",
    "for i in range(0, len(d.index)):\n",
    "    empty.append(0)\n",
    "\n",
    "map = {'price': empty}\n",
    "for add in to_add:\n",
    "    map[add] = empty\n",
    "\n",
    "additional = pd.DataFrame(map)\n",
    "\n",
    "test = test.join(d)\n",
    "test = test.join(additional)\n",
    "to_drop = ['location attributes'] + list(test_tags.difference(tags))\n",
    "test = test.drop(to_drop, axis=1)\n",
    "\n",
    "target = 'price'\n",
    "columns = train.columns.tolist()\n",
    "columns = [c for c in columns if c not in [\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_error</th>\n",
       "      <th>std_test_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1300</td>\n",
       "      <td>6.520662e+09</td>\n",
       "      <td>2.454553e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1100</td>\n",
       "      <td>6.653452e+09</td>\n",
       "      <td>2.479403e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500</td>\n",
       "      <td>6.657138e+09</td>\n",
       "      <td>2.535673e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900</td>\n",
       "      <td>6.828559e+09</td>\n",
       "      <td>2.557727e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700</td>\n",
       "      <td>6.957095e+09</td>\n",
       "      <td>2.539434e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>7.181199e+09</td>\n",
       "      <td>2.618706e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300</td>\n",
       "      <td>7.616456e+09</td>\n",
       "      <td>2.559157e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>9.092941e+09</td>\n",
       "      <td>2.504205e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators  mean_test_error  std_test_error\n",
       "6               1300     6.520662e+09    2.454553e+09\n",
       "5               1100     6.653452e+09    2.479403e+09\n",
       "7               1500     6.657138e+09    2.535673e+09\n",
       "4                900     6.828559e+09    2.557727e+09\n",
       "3                700     6.957095e+09    2.539434e+09\n",
       "2                500     7.181199e+09    2.618706e+09\n",
       "1                300     7.616456e+09    2.559157e+09\n",
       "0                100     9.092941e+09    2.504205e+09"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': range(100, 1501, 200),\n",
    "    # 2. 'max_depth': range(5, 71, 5),\n",
    "    # 2. 'min_samples_split': range(100, 1101, 200),\n",
    "    # 3. 'max_features': range(7, 20, 2),\n",
    "    # 4. 'subsample': [0.6,0.7,0.75,0.8,0.85,0.9]\n",
    "}\n",
    "\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate = 0.1, min_samples_split=180, min_samples_leaf = 50,\n",
    "                                 max_features='sqrt', subsample=0.8, max_depth= 8)\n",
    "search_cv = GridSearchCV(estimator=gbr, \n",
    "                   param_grid=param_distributions,\n",
    "                   scoring = 'neg_mean_squared_error', \n",
    "                   verbose=3,\n",
    "                   error_score='raise',\n",
    "                   n_jobs=-1)\n",
    "\n",
    "search_cv.fit(train[columns], train[target])\n",
    "\n",
    "columns = [f\"param_{name}\" for name in param_distributions.keys()]\n",
    "columns += [\"mean_test_error\", \"std_test_error\"]\n",
    "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
    "cv_results[\"mean_test_error\"] = -cv_results[\"mean_test_score\"]\n",
    "cv_results[\"std_test_error\"] = cv_results[\"std_test_score\"]\n",
    "cv_results[columns].sort_values(by=\"mean_test_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed error: 72165.93501543833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = GradientBoostingRegressor(learning_rate=0.1, n_estimators = 900, max_leaf_nodes= 50, min_samples_split=25, subsample=0.8, random_state= 0, max_features=17, max_depth=50)\n",
    "training = train.sample(frac=0.7, random_state=5)\n",
    "test = train.loc[~train.index.isin(training.index)]\n",
    "clf.fit(training[columns], training[target])\n",
    "clf = clf.predict(test[columns])\n",
    "# Compute error between our test predictions and the actual values.\n",
    "lin_mse = mean_squared_error(clf, test[target], squared=False)\n",
    "print(\"Computed error:\", lin_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the result\n",
    "result = pd.DataFrame(clf)\n",
    "result.to_csv(\"result.csv\", header=['price'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31e71d7ed0fa0b4c5d8ce44b530b41ec61e7cc3af5332ca9786b8048d514a256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
